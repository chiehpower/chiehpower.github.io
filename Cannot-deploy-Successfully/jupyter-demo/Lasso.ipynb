{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "Load the scikit-learn version of the diabetes dataset and use the load_diabetes function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the data of DESCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes dataset\n",
      "================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "Data Set Characteristics:\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attributes:\n",
      "    :Age:\n",
      "    :Sex:\n",
      "    :Body mass index:\n",
      "    :Average blood pressure:\n",
      "    :S1:\n",
      "    :S2:\n",
      "    :S3:\n",
      "    :S4:\n",
      "    :S5:\n",
      "    :S6:\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(diabetes.DESCR)\n",
    "#print(diabetes['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "Split the dataset into the training and test sets by using the function train_test_split in scikit-learn. <p>\n",
    "Here random_state is set my birthday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes['data'],diabetes['target'], random_state=2209)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "Below is the training and test R2 for the Lasso model with the default parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.36\n",
      "Test set score: 0.37\n",
      "Number of features used: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0.        ,  -0.        , 386.09999602,   0.        ,\n",
       "         0.        ,   0.        ,  -0.        ,   0.        ,\n",
       "       318.17739949,   0.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(random_state=2209).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso.score(X_test, y_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso.coef_ != 0)))\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Question1:<p>\n",
    "Training set score: 0.32,\n",
    "Test set score: 0.33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question2:<p> \n",
    "The coefficients remain the 2, and it means those including two features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question3:<p> \n",
    "We can see the attribute of DESCR that shows by order and compare the array of lasso.coed_.<p>\n",
    "Attributes:Age,Sex,Body mass index,Average blood pressure,S1,S2,S3,S4,S5,S6<p> \n",
    "The name of features are \"Body mass index\" and \"S5\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 \n",
    "I loaded the original dataset of diabetes from the web page and used the np.loadtxt about dtype=str then cut the header (first) row.<p>\n",
    "Second, I transform the type from str to float before I split the data and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_diabetes = np.loadtxt(fname=\"C:/Users/USER/diabetes.data\",dtype='str')\n",
    "load_diabetes = load_diabetes[1:,:]\n",
    "load_diabetes = load_diabetes.astype(np.float)\n",
    "XX = load_diabetes[:,:-1]\n",
    "yy = load_diabetes[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5\n",
    "I split the dataset into the training and test sets by using the function train_test_split in scikit-learn. <p>\n",
    "And the random_state is set the 2209."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (331, 10)\n",
      "X_test:  (111, 10)\n",
      "y_train:  (331, 1)\n",
      "y_test:  (111, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX,yy, random_state=2209)\n",
    "print(\"X_train: \",XX_train.shape)\n",
    "print(\"X_test: \",XX_test.shape)\n",
    "print(\"y_train: \",yy_train.shape)\n",
    "print(\"y_test: \",yy_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6\n",
    "Repeat Step 3 for the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(random_state=2209).fit(XX_train, yy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.53\n",
      "Test set score: 0.43\n",
      "Number of features used: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score: {:.2f}\".format(lasso.score(XX_train, yy_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso.score(XX_test, yy_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it use the default parameter for alpha, we can still see its number of features used which is 8. <p> \n",
    "Because the original data didn't do the normalisation, the prediction result is not correct. The data should subtract mean and divide by std."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7\n",
    "Preprocess the training and test sets in the same way by using StandardScaler()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "load_diabetes = np.loadtxt(fname=\"C:/Users/USER/diabetes.data\",dtype='str')\n",
    "load_diabetes = load_diabetes[1:,:]\n",
    "load_diabetes = load_diabetes.astype(np.float)\n",
    "\n",
    "# I do the normalisation by StandardScaler() for all the original data including the data and target.\n",
    "# Then I divide the original data into data (Scaler_Xsc) and target (Scaler_ysc).\n",
    "scaler = StandardScaler()\n",
    "Scaler_load_diabetes = scaler.fit_transform(load_diabetes) \n",
    "Scaler_Xsc = Scaler_load_diabetes[:,:-1]\n",
    "Scaler_ysc = Scaler_load_diabetes[:,-1:]                                \n",
    "\n",
    "Xsc_train, Xsc_test, ysc_train, ysc_test = train_test_split(Scaler_Xsc,Scaler_ysc, random_state=2209)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.00\n",
      "Test set score: -0.00\n",
      "Number of features used: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "Sclasso = Lasso(random_state=2209).fit(Xsc_train, ysc_train)\n",
    "print(\"Training set score: {:.2f}\".format(Sclasso.score(Xsc_train, ysc_train)))\n",
    "print(\"Test set score: {:.2f}\".format(Sclasso.score(Xsc_test, ysc_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(Sclasso.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, I want to describe more detail about what I try the results. As I couldn't get the same scale of data, I spent a lot of time to find the reasons for the StandardScale(). After I only used the StandardScale() for X_train and X_test of original data and then the array values are different with the data from sklearn. First, we know that the StandardScale() is (X-mean)/(standard deviation), and I use the respective function to compute then the scale is between 10^-2 and 10^-1; however, if we use the StandardScale() for the X data which show the scale between 10^-1 and 10^0.\n",
    "```\n",
    "Xsc = load_diabetes[:,:-1]\n",
    "Scaler_ysc = Scaler_load_diabetes[:,-1:]\n",
    "Scaler_ysc = load_diabetes[:,-1:]\n",
    "Scaler_Xsc = (Xsc - np.mean(Xsc)) / np.std(Xsc)\n",
    "```\n",
    "Furthermore, the result which only using the StandardScale() on X train and X test is wrong, because the coefficient numbers should shrink close to zero at alpha=1. The value of number of features used is bigger at alpha=1, and if we increase the alpha, the number of features used can't still sharply decrease. In my opinion, I think that the situation is more similar to Ridge regression. <p> \n",
    "Sequentially, I changed the way that doing the StandardScale() for all data including the X data and Y data, after the step was loading the original data.(i.e. Step7)\n",
    "```\n",
    "scaler = StandardScaler()\n",
    "Scaler_load_diabetes = scaler.fit_transform(load_diabetes) \n",
    "Scaler_Xsc = Scaler_load_diabetes[:,:-1]\n",
    "Scaler_ysc = Scaler_load_diabetes[:,-1:]   \n",
    "```\n",
    "We can notice that the new value of number of features used is more normal than value of previous way. In the default parameter of alpha=1, the number of features used can be 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9 \n",
    "In this step, I used the different alpha parameters in the Lasso, and plot the test R2 vs the number of features used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.54\n",
      "Test set score: 0.42\n",
      "Number of features used: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.01036117, -0.19463279,  0.32543035,  0.19858646, -0.08370899,\n",
       "       -0.        , -0.13641493,  0.0062725 ,  0.35905022,  0.0183304 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso001 = Lasso(alpha=0.01,max_iter=100000,random_state=2209).fit(Xsc_train, ysc_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso001.score(Xsc_train, ysc_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso001.score(Xsc_test, ysc_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso001.coef_ != 0)))\n",
    "lasso001.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.54\n",
      "Test set score: 0.41\n",
      "Number of features used: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.02299423, -0.21518025,  0.32462825,  0.21510158, -0.43468459,\n",
       "        0.2567307 ,  0.0170406 ,  0.07704454,  0.47972704,  0.02505472])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso0001 = Lasso(alpha=0.001,max_iter=100000,random_state=2209).fit(Xsc_train, ysc_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso0001.score(Xsc_train, ysc_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso0001.score(Xsc_test, ysc_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso0001.coef_ != 0)))\n",
    "lasso0001.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.49\n",
      "Test set score: 0.46\n",
      "Number of features used: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.        , -0.03944713,  0.30976222,  0.10734754, -0.        ,\n",
       "       -0.        , -0.05896764,  0.        ,  0.28447255,  0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso01 = Lasso(alpha=0.1,max_iter=100000,random_state=2209).fit(Xsc_train, ysc_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso01.score(Xsc_train, ysc_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso01.score(Xsc_test, ysc_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso01.coef_ != 0)))\n",
    "lasso01.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha=0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.06\n",
      "Test set score: 0.05\n",
      "Number of features used: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.        ,  0.04921435,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso055 = Lasso(alpha=0.55,max_iter=100000,random_state=2209).fit(Xsc_train, ysc_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso055.score(Xsc_train, ysc_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso055.score(Xsc_test, ysc_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso055.coef_ != 0)))\n",
    "lasso055.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.12\n",
      "Test set score: 0.12\n",
      "Number of features used: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.        ,  0.08659468,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.02796178,  0.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso05 = Lasso(alpha=0.5,max_iter=100000,random_state=2209).fit(Xsc_train, ysc_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso05.score(Xsc_train, ysc_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso05.score(Xsc_test, ysc_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso05.coef_ != 0)))\n",
    "lasso05.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.42\n",
      "Test set score: 0.42\n",
      "Number of features used: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.        ,  0.27694174,  0.03935842,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.23947988,  0.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso02 = Lasso(alpha=0.2,max_iter=100000,random_state=2209).fit(Xsc_train, ysc_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso02.score(Xsc_train, ysc_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso02.score(Xsc_test, ysc_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso02.coef_ != 0)))\n",
    "lasso02.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.52\n",
      "Test set score: 0.45\n",
      "Number of features used: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.        , -0.1282557 ,  0.31392643,  0.15786137, -0.        ,\n",
       "       -0.00187181, -0.1214413 ,  0.        ,  0.30438111,  0.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso005 = Lasso(alpha=0.05,max_iter=100000,random_state=2209).fit(Xsc_train, ysc_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso005.score(Xsc_train, ysc_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso005.score(Xsc_test, ysc_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso005.coef_ != 0)))\n",
    "lasso005.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha=0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.53\n",
      "Test set score: 0.44\n",
      "Number of features used: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.        , -0.16139804,  0.32017444,  0.1785554 , -0.04057944,\n",
       "       -0.        , -0.13200144,  0.        ,  0.33389872,  0.00108197])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso003 = Lasso(alpha=0.03,max_iter=100000,random_state=2209).fit(Xsc_train, ysc_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso003.score(Xsc_train, ysc_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso003.score(Xsc_test, ysc_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso003.coef_ != 0)))\n",
    "lasso003.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha=0.015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.54\n",
      "Test set score: 0.43\n",
      "Number of features used: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.00361313, -0.18664006,  0.3238213 ,  0.19267387, -0.07061239,\n",
       "       -0.        , -0.13917783,  0.        ,  0.35276204,  0.01356185])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso0015 = Lasso(alpha=0.015,max_iter=100000,random_state=2209).fit(Xsc_train, ysc_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso0015.score(Xsc_train, ysc_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso0015.score(Xsc_test, ysc_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso0015.coef_ != 0)))\n",
    "lasso0015.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.00\n",
      "Test set score: -0.00\n",
      "Number of features used: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso2 = Lasso(alpha=2,max_iter=100000,random_state=2209).fit(Xsc_train, ysc_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso2.score(Xsc_train, ysc_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso2.score(Xsc_test, ysc_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso2.coef_ != 0)))\n",
    "lasso2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha=0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.45\n",
      "Test set score: 0.45\n",
      "Number of features used: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.        ,  0.29824698,  0.0685637 , -0.        ,\n",
       "       -0.        , -0.01555222,  0.        ,  0.26405987,  0.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso015 = Lasso(alpha=0.15,max_iter=100000,random_state=2209).fit(Xsc_train, ysc_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso015.score(Xsc_train, ysc_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso015.score(Xsc_test, ysc_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso015.coef_ != 0)))\n",
    "lasso015.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "α=0.001 Number of features used: 10\n",
      "α=0.01 Number of features used: 9\n",
      "α=0.015 Number of features used: 8\n",
      "α=0.03 Number of features used: 7\n",
      "α=0.05 Number of features used: 6\n",
      "α=0.1 Number of features used: 5\n",
      "α=0.15 Number of features used: 4\n",
      "α=0.2 Number of features used: 3\n",
      "α=0.5 Number of features used: 2\n",
      "α=0.55 Number of features used: 1\n",
      "α=1 Number of features used: 0\n",
      "α=2 Number of features used: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"α=0.001 Number of features used: {}\".format(np.sum(lasso0001.coef_ != 0)))\n",
    "print(\"α=0.01 Number of features used: {}\".format(np.sum(lasso001.coef_ != 0)))\n",
    "print(\"α=0.015 Number of features used: {}\".format(np.sum(lasso0015.coef_ != 0)))\n",
    "print(\"α=0.03 Number of features used: {}\".format(np.sum(lasso003.coef_ != 0)))\n",
    "print(\"α=0.05 Number of features used: {}\".format(np.sum(lasso005.coef_ != 0)))\n",
    "print(\"α=0.1 Number of features used: {}\".format(np.sum(lasso01.coef_ != 0)))\n",
    "print(\"α=0.15 Number of features used: {}\".format(np.sum(lasso015.coef_ != 0)))\n",
    "print(\"α=0.2 Number of features used: {}\".format(np.sum(lasso02.coef_ != 0)))\n",
    "print(\"α=0.5 Number of features used: {}\".format(np.sum(lasso05.coef_ != 0)))\n",
    "print(\"α=0.55 Number of features used: {}\".format(np.sum(lasso055.coef_ != 0)))\n",
    "print(\"α=1 Number of features used: {}\".format(np.sum(Sclasso.coef_ != 0)))\n",
    "print(\"α=2 Number of features used: {}\".format(np.sum(lasso2.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha | Number  \n",
    ":----:|:-----:\n",
    "1 | 0 \n",
    "0.55 | 1\n",
    "0.5|2\n",
    "0.2|3\n",
    "0.15|4\n",
    "0.1|5\n",
    "0.05|6\n",
    "0.03|7\n",
    "0.015|8\n",
    "0.01|9\n",
    "0.001|10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Test R^2 score')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAFuCAYAAACmzO7fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline   \n",
    "plt.plot(np.sum(lasso0001.coef_ != 0),lasso0001.score(Xsc_test, ysc_test), '^', label=\"Lasso alpha=0.001\")\n",
    "plt.plot(np.sum(lasso001.coef_ != 0),lasso001.score(Xsc_test, ysc_test), '<', label=\"Lasso alpha=0.01\")\n",
    "plt.plot(np.sum(lasso0015.coef_ != 0),lasso0015.score(Xsc_test, ysc_test), '^', label=\"Lasso alpha=0.015\")\n",
    "plt.plot(np.sum(lasso003.coef_ != 0),lasso003.score(Xsc_test, ysc_test), '>', label=\"Lasso alpha=0.03\")\n",
    "plt.plot(np.sum(lasso005.coef_ != 0),lasso005.score(Xsc_test, ysc_test), '^', label=\"Lasso alpha=0.05\")\n",
    "plt.plot(np.sum(lasso01.coef_ != 0),lasso01.score(Xsc_test, ysc_test), 'v', label=\"Lasso alpha=0.1\")\n",
    "plt.plot(np.sum(lasso015.coef_ != 0),lasso015.score(Xsc_test, ysc_test), '>', label=\"Lasso alpha=0.15\")\n",
    "plt.plot(np.sum(lasso02.coef_ != 0),lasso02.score(Xsc_test, ysc_test), '^',label=\"Lasso alpha=0.2\")\n",
    "plt.plot(np.sum(lasso05.coef_ != 0),lasso05.score(Xsc_test, ysc_test), 'd', label=\"Lasso alpha=0.5\")\n",
    "plt.plot(np.sum(lasso055.coef_ != 0),lasso055.score(Xsc_test, ysc_test), 'D', label=\"Lasso alpha=0.55\")\n",
    "plt.plot(np.sum(Sclasso.coef_ != 0),Sclasso.score(Xsc_test, ysc_test), 's', label=\"Lasso alpha=1\")\n",
    "plt.plot(np.sum(lasso2.coef_ != 0),lasso2.score(Xsc_test, ysc_test), '*', label=\"Lasso alpha=2\")\n",
    "\n",
    "\n",
    "plt.xticks([0,1,2,3,4,5,6,7,8,9,10])\n",
    "my_y_ticks=np.arange(-0.1, 0.51, 0.05)\n",
    "plt.yticks(my_y_ticks)\n",
    "plt.legend(ncol=2,loc=(0,1.05))\n",
    "plt.xlabel(\"Number of features used\")\n",
    "plt.ylabel(\"Test R^2 score\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prefer the point which is at alpha = 0.1, because we can see the point at alpha=0.1 which has the highest score. Second, the numbers of features used are underfitting between 0 and 2. Although decreasing features can help us to analyze the data, too few features will make us infer errors. On the other hand, the numbers of features used are overfitting between 7 and 10. According to the plot, after alpha=0.1, the curve decrease steadily obviously. In conclusion, the numbers of features used at the alpha=0.1 can get the highest score that it is reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10\n",
    "I use the different alpha parameters for the Lasso by using cross-validation on the training set. After CV got the best value of alpha, we took this value the training set and did the test score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.077\n",
      "Best mean(scores): 0.5057245\n",
      "Training set score: 0.50\n",
      "Test set score: 0.46\n",
      "Number of features used: 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "col = 0\n",
    "Avalue = 0\n",
    "step = 0\n",
    "alphaNP=np.arange(0.001, 1, 0.001)\n",
    "for i in alphaNP:\n",
    "    lasso = Lasso(alpha=i,max_iter=10000,random_state=2209,tol=0.0001)\n",
    "    scores = cross_val_score(lasso,X_train,y_train,cv=5)\n",
    "    score = round(np.mean(scores),7)\n",
    "    step += 1\n",
    "    if col < score :\n",
    "        col = score\n",
    "        Avalue = i\n",
    "print(\"Best Alpha:\", Avalue)\n",
    "print(\"Best mean(scores):\", col)\n",
    "lasso = Lasso(alpha=Avalue,max_iter=100000,random_state=2209).fit(Xsc_train, ysc_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso.score(Xsc_train, ysc_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso.score(Xsc_test, ysc_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step, we can see the result which alpha=0.1 is the highest score and the range is quite high score between 0.15 and 0.05. It can help us judge that the range of the highest score will probably fall there. After using CV, we can get the best alpha 0.077 and it is close to 0.1. The best number of features used is also 5 as same as 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11\n",
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX,yy, random_state=2209)\n",
    "X_training_proper, X_calibration, y_training_proper, y_calibration = train_test_split(XX_train,yy_train, test_size=99, random_state=2209)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "Scaler_X_test = scaler.fit_transform(XX_test) \n",
    "Scaler_X_training_proper = scaler.fit_transform(X_training_proper) \n",
    "Scaler_X_calibration = scaler.fit_transform(X_calibration) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proper_lasso = Lasso(random_state=2209).fit(Scaler_X_training_proper, y_training_proper)\n",
    "new_prediction = proper_lasso.predict(X_calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
