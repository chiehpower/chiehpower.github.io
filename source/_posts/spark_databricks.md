---
title: Databricks ä½¿ç”¨æµç¨‹
description: <center> ä»‹ç´¹å¦‚ä½•è¼•é¬†åœ¨Databricksä¸Šæ“ä½œSparkã€‚ </center>
photos:
  - 'https://lh3.googleusercontent.com/R5LU72iR_Jldl9qecsMdy0W1cGQn-__taWMCuCiHCIiYSggrRmFD2uaWdBv06WdCH4OX-85IFzgN-JmfBtzaGqiBxrfhSJVWicxL_kEW95gQlDWhULtznDYVh0qpW-S-3fQvfFW1_Ncc5VDqontgbOWkkNE3vNs53t6zUFvNVPWkdA6r55-LqbhU5VR8qpS98b98MSAfI88b4sdFVjnxvtxJSVeBmUCfvaD0hni92fyEQT9QrKGUwYE006hE4mBSW4s4UwUJuIPGaqMY5KK7NKilQqk5Tqs6HtMMFMaVovMqYebjFb4VxCdE6NFhVqx5zPokSt81s2TWggQu2nNJCiA_jjBSU5pvcIrKyQo9MXrl1_mJsC3fVtp9oNE-ZEZ7MMnkUx6sT-sHhKPtZ6BnPKNz-DoaYIOF39QD6gswS2FsIml-raOvhZh2qaYAc9xyUSjymWt1IjIrTqEwQjG1RS4yOtUpYqmKS3x2870DoltgqHrGtTQF9TYPbBW3YpDGVGjFfeCXyH51O_2ua0E1G5C2p9-g4JIRBaKp6xhebXhdD5EvCkH-sm88mERT-sL6To57dpF5IYjVCBblcy_YHDHctV1kboxQeL6jdS3XlTUo7l6ghszlymUT3ACE801NjKQNKzdloZRmChn3Kk3CfB-251R90zQSqRa_ulRZSpvsbHhIE3IzJ5t3DNlD41k7GvvZU97uxvvzXgroLB1sr7MqaA=w2160-h1216-no'
date: 2019-03-12 13:04:23
tags: [Spark, Pyspark, Hadoop, Colab, Notes, Program, Databricks]
categories: Program
password:
---
ä½¿ç”¨Sparkæœ‰ä¸€å€‹ä¸éŒ¯çš„å¹³å°ã€Databricksã€ï¼Œé›–ç„¶å¾Œä¾†å·²ä¸ä½¿ç”¨ï¼¸ï¼¤ è½‰æˆ°åˆ°Colabä¸Šæ“ä½œã€‚
å› ç‚ºDatabrickså…è²»ä½¿ç”¨æœ‰å€‹ç¼ºé»ï¼Œå®¹æ˜“æ™‚é–“ä¸€é•·å°±è¦é‡æ–°å‰µå»ºClusterã€‚
ç•¶ç„¶ä½¿ç”¨é€™å€‹å¥½è™•æ˜¯å¯ä»¥ä¸ç”¨ä½¿ç”¨åˆ°æœ¬æ©Ÿçš„è³‡æºã€‚

é¦–å…ˆï¼Œå¦‚æœè¦æ‰¾ç™»å…¥å¸³è™Ÿçš„é é¢ï¼Œåœ¨googleé¦–é ç›´æ¥æ‰“ä¸Š`databricks account login`ï¼Œé»é¸ç¬¬ä¸€å€‹`Login - Databricks Community Edition`

é€²å…¥ä¹‹å¾Œæœƒçœ‹åˆ°é€™å€‹ç•«é¢ã€‚
![databrick](/images/databricks_1.png)

æˆ‘å€‘å¯ä»¥çœ‹åˆ°æ—é‚Šæœ‰ä¸€äº›é¸é …:
1. Home
2. Workspaceï¼šè£¡é¢æœƒå„²å­˜æ‰€æœ‰çš„importæª”æ¡ˆ
3. Recents
4. Data
5. Clustersï¼šæ¯å€‹æª”æ¡ˆéƒ½éœ€è¦æœ‰ä¸€å€‹clusterä¾†åšæ”¯é…ã€‚
6. Jobs
7. Search

æˆ‘å€‘æœƒç”¨åˆ°çš„æ˜¯ `Workspace` ï¼† `Clusters`éƒ¨åˆ†ã€‚

{% cq %}ç¸½å…±æœ‰å…©å¤§Stepsï¼Œé¦–å…ˆç¬¬ä¸€æ­¥æ˜¯è¦å…ˆå‰µé€ ä¸€å€‹Clusterã€‚
å†ä¾†æ˜¯æˆ‘å€‘è¦æŠŠæˆ‘å€‘çš„file import é€²å» Databricksã€‚{% endcq %}

# Create Clusters 
é»æ“Šå·¦å´çš„Clustersï¼Œè£¡é¢åˆ—å‡ºæ‰€æœ‰çš„å·²å‰µå»ºæˆ–é‚„æœªå‰µå»ºçš„ç¾¤é›†ã€‚
å‰›ç™»å…¥çš„æ™‚å€™(æˆ–ä¸€èˆ¬éäº†ä¸€æ®µæ™‚é–“ä¹‹å¾Œä»–æœƒåœæ­¢ï¼Œéœ€é‡å‰µ)ï¼Œæˆ‘å€‘å…ˆå‰µå»ºä¸€å€‹ã€‚é»æ“Šä¸Šæ–¹çš„`âœš Create Cluster`ä¹‹å¾Œæœƒçœ‹åˆ°ä¸‹æ–¹çš„ç•«é¢ã€‚
![databrick](/images/databricks_2.png)

å¯ä»¥éš¨æ„èµ·å€‹Cluster Nameï¼Œæˆ‘å€‘é¸æ“‡æœ€æ–°çš„Databricks Runtime Versionç‰ˆæœ¬å§ï¼Python Versioné¸æ“‡3ï¼Œç„¶å¾Œå…¶ä»–å¯ä»¥ä¸ç”¨å‹•ï¼Œæœ€å¾Œå°±æ˜¯Create Clusterã€‚
ä¸€é–‹å§‹stateæ˜¯Pendingï¼Œç­‰å€‹å¹¾ç§’é˜è®“ä»–è™•ç†ä¸€ä¸‹ï¼Œç•¶stateè®ŠæˆRunningæ™‚ï¼Œé€™æ¨£å°±å‰µå»ºæˆåŠŸå›‰ï¼

# Create file
å†ä¾†æˆ‘å€‘å¯ä»¥åˆ°Workspace areaï¼Œå¦‚æœæ˜¯ä¸€é–‹å§‹ä½¿ç”¨æ˜¯ç©ºçš„ï¼Œæˆ‘å€‘å¯ä»¥é¸æ“‡Createä¸€å€‹ç©ºç™½çš„fileï¼Œæˆ–è€…è¦import fileé€²å»éƒ½å¯ä»¥ã€‚
æŒ‰å³éµï¼Œæˆ–å‡ºç¾Create & Importã€‚
![databrick](/images/databricks_3.png)
é¸æ“‡Create file > Notebookï¼Œä¹‹å¾Œæœƒè·³å‡ºè¦–çª—å¡«å…¥file nameã€é¸æ“‡ä½¿ç”¨çš„èªè¨€sparkå¯ä»¥ä½¿ç”¨å››ç¨®èªè¨€ï¼Œå€‹äººä½¿ç”¨Pythonï¼Œæœ€å¾Œå°±æ˜¯é»é¸æˆ‘å€‘å‰›å‰›å‰µå»ºçš„clusterã€‚å®Œæˆä¹‹å¾Œå°±å‰µå»ºæˆåŠŸã€‚
![databrick](/images/databricks_4.png)
æˆ‘å€‘ç›´æ¥type scï¼Œshift+enterï¼Œå¯ä»¥çœ‹è¦‹`Out[1]: <SparkContext master=local[8] appName=Databricks Shell>`ï¼Œå®Œæˆã€‚

å¦‚æœæ˜¯import fileçš„äººï¼Œè¨˜å¾—åœ¨Detachedé»é¸æˆ‘å€‘å‰›å‰µå»ºçš„Clusterã€‚
ç„¶å¾Œå°±å¯ä»¥é‹è¡Œæˆ‘å€‘çš„codeäº†ã€‚
![databrick](/images/databricks_5.png)

ä¸éä¸€æ®µæ™‚é–“å°±éœ€è¦å†é‡æ–°æ“ä½œä¸€æ¬¡clusteræµç¨‹... lol
ç•¶ç„¶æœ‰å¦ä¸€å€‹æ“‡ä¸­è¾¦æ³•å°±æ˜¯ä½¿ç”¨Colabï¼Œæˆ‘è¦ºå¾—ç›¸å°æ–¹ä¾¿è¨±å¤šğŸ¤”

ğŸ‘‰å¯ä»¥åƒè€ƒé€™ç¯‡[Install pyspark Ã— Use on Jupyter notebook Ã— Colab](https://chiehpower.com/2019/03/12/install-spark/)